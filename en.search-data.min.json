[{"id":0,"href":"/Database/","title":"Database","parent":"@hwangseonbi","content":""},{"id":1,"href":"/DevOps/","title":"DevOps","parent":"@hwangseonbi","content":""},{"id":2,"href":"/Frontend/","title":"Frontend","parent":"@hwangseonbi","content":""},{"id":3,"href":"/Posts/","title":"Posts","parent":"@hwangseonbi","content":""},{"id":4,"href":"/DevOps/1688b1f5-d4f2-4c98-9940-ab8592717211/","title":"Kubernetes configuration pattern에 대하여","parent":"DevOps","content":" 이 블로그는 Notion에서 랜더링 자동화를 통해 제작되었습니다.\nNotion 페이지에 최적화되어있습니다. → Notion에서 보기\n   1. EnvVar Configuration 2. Configuration Resouece 3. Immutable Configuration    1) Docker 2) Kubernetes     4. Configuration Template    Kubernetes Pattern\nPart IV. Configuration Patterns 참고\n 1. EnvVar Configuration    가장 간단한 방법이다. Config Data의 개수가 적고 단순할 때 사용하기 적합하다.\n  default ENV는 이미지에 정의해준다.\n1 2 3 4 5 6  FROMubuntu:latestENV BACKEND_URL \u0026#34;/backend\u0026#34;ENV PROFILE = \u0026#34;DEV\u0026#34;...\t     어플리케이션에서 접근한다. 환경변수로 PROFILE만 주입해주고 어플리케이션 내부에서 PROFILE에 따라 다른 config를 불러오는 것도 하나의 방법이다. (많이 쓰임)\n1 2 3 4 5  contentsTableRefresh:function(){ const url = `${process.env.BACKEND_URL}/videos/contents` fetch(url) ...      Kubernetes 정의 파일에서 env를 주입한다. 문자열로 직접 삽입할 수도 있으며 configMap이나 Secret을 참조하여 받아올 수도 있다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  apiVersion:v1kind:Podmetadata:name:random-generatorspec:containers:- image:my/jsproject:1.0name:jsprojectenv:- name:BACKEND_URLvalue:http://localhost:8080- name :PROFILEvalueFrom:...      장점\n  간편하다.\n  어떤 어플리케이션이든, 어떤 베이스 이미지든 통용되므로 범용성이 좋다.\n  단점\n  안전하지 않다.\n  복잡한 Config를 다루기에는 맞지 않다. (그 많은걸 어떻게 다 핸들링할것인가!)\n  ENV를 주입할 수 있는 계층이 나눠져 있어서 디버깅하기 어렵다. (Image에서 정의될 수도, K8S정의에서 정의될 수도, APP에서 정의될 수도 있으니..)\n  Immutable 하다. 즉 APP이 시작되기 전에 세팅되서 나중에 변경하기 힘들다. → Rolling update할 때 config 바뀔일이 없으니 장점일 수도? 암튼!\n  2. Configuration Resouece    위 EnvVar Configuration 패턴에서 조금 변형된 패턴이다.\n이 패턴을 사용하면 좋은 점\n  config로 사용할 데이터들을 하나의 지점에서 관리할 수 있다.\n  configMap을 Pod에서 파일로 마운트 시키면 configMap 변경 사항이 반영되게 할 수도 있다.\n  EnvVar Conf 패턴에서는 Pod 정의에 env를 직접 문자열로 때려넣었다면 이 패턴에서는 K8S 네이티브 리소스인 ConfigMap과 Secret를 사용하여 넣는 것이다. ConfigMap과 Secret은 기술적으로는 동일하고 사용법도 동일하다.\n물론 제한 사항도 있으니 체크필요! (ex. Secret은 1MB 제한)\n1 2 3 4 5 6 7 8 9 10 11 12  apiVersion:v1kind:ConfigMapmetadata:name:my-configdata:BACKEND_URL:/backendapplication.properties:|# App properties configlog.file=/tmp/myapp.logserver.port=7070EXTRA_OPTIONS:\u0026#34;high-secure,native\u0026#34;...   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  apiVersion:v1kind:Podmetadata:name:random-generatorspec:containers:- image:my/application:1.0name:myapplicationvolumeMounts:- name:config-volumemountPath:/config- env:- name:BACKEND_URLvalueFrom:configMapKeyRef:name:my-configkey:BACKEND_URLprefix:CONFIG_volumes:- name:config-volumeconfigMap:name:my-config   💡참고 : **Secret은 그다지 secret하지 않다. 그러므로 민감한 정보라면 어플리케이션 단에서도 암호화할 필요가 있다. -** Secure은 Base64로 인코딩되어 저장되어있다. 그리고 파드에 넣어지기 직전에 디코딩된다. - Secret의 아래와 같은 특징이 있긴하다. - Secret은 Pod가 실행되고있는 노드에만 배포된다. - 해당 노드에서 secret은 메모리에 저장된다. pod가 제거되면 같이 제거된다. - ETCD에서 secret은 암호화된 형태로 저장된다. - 그래도 어쨌든 root user가 아닌 user도 접근해서 볼 수 있다. (role-based access control 적용하더라도, pod 생성 권한만 있으면 마운트시켜서 볼 수 있음) \n3. Immutable Configuration    이 패턴을 사용하면 좋은점\n  Immutability 컨트롤 가능\n envVar config 패턴에서는 immutability가 패시브로 강제였지만 여기서의 immutability는 원하는 시점에 immutable하게 할 수 있다는 뜻. 예를들면 어플리케이션이 시작되고나면 바꿀수 없게 한다던지.    config의 버전관리 가능\n  ConfigMap이나 Secret의 용량제한을 뛰어넘을 수 있음\n  How?\nconfig 관리 컨테이너 이미지를 만들어놓고 어플리케이션 런타임 때 이 컨테이너를 참조한다. 참조하는 방법은 플랫폼에 따라서 다양한 방법으로 가능.\n1) Docker    volume-from 옵션으로 다른 컨테이너의 volume 참조\n1 2 3 4 5  docker create --name config-dev myapplication-config-dev:1.0.1 docker run --volume-from config-dev myapplication:1.0 docker create --name config-prdt myapplication-config-prdt:1.0.1 docker run --volume-from config-prdt myapplication:1.0        2) Kubernetes    Kubernetes에서는 Docker의 volume-from 같은 명령을 지원하지 않는다. 다른 방법이 있는데 Init Container을 사용하면 된다.\n1 2 3  FROMbusyboxADD dev.properties /config-src/demo.propertiesENTRYPOINT [\u0026#34;sh\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;cp /config-src/* $1\u0026#34;, \u0026#34;--\u0026#34;]   Deployment의 Pod 템플릿에서는 하나의 volume과 두개의 컨테이너를 가지게된다.\n     1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  ...initContainers:- image:k8s/patterns/config-dev:1name:initargs:- \u0026#34;/config\u0026#34;volumeMounts:- mountPath:\u0026#34;/config\u0026#34;name:config-directorycontainers:- image:k8spatterns/demo:1name:demoports:- containerPort:8080name:httpprotocol:TCPvolumeMounts:- mountPath:\u0026#34;/config\u0026#34;name:config-directoryvolumes:- name:config-directoryemptyDir:{}    \u0026ldquo;config-directory\u0026quot;라는 이름의 volume을 통해서 initContainers를 거쳐 실제 app 컨테이너로 config가 카피된다.  만약 config를 현재 dev에서 prdt로 바꾸고 싶다면, init container의 image만 바꾸면 된다. (yaml을 통해서든 kubectl을 통해서든) 근데 이방법도 안전하지 않은데?? 그리고 hot reload도 안될듯..\nOpenShift Template에서는 이 부분은 쉽게 파라미터를 넘기는 식으로 사용가능하다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  apiVersion:v1kind:Templatemetadata:name:demoparameters:- name:CONFIG_IMAGEdescription:Name of configuration imagevalue:k8spatterns/config-dev:1objects:- apiVersion:v1kind:DeploymentConfig// ...spec:template:metadata://...spec:initContainers:- name:initimage:${CONFIG_IMAGE}args:[\u0026#34;/config\u0026#34;]volumeMounts:- mountPath:/configname:config-directorycontainers:- image:k8spatterns/demo:1//...volumeMounts:- mountPath:/configname:config-directoryvolumes:- name:config-directoryemptyDir:{}   1  oc new-app demp -p CONFIG_IMAGE=k8spatterns/config-prod:1   책에서 말하는 장점과 단점은 아래와 같다.\n장점\n  container 내부에 config가 들어있으므로 버전관리가 가능하다.\n  Configuration created this way can be distributed over a container registry. The configuration can be examined even without accessing the cluster. → \u0026ldquo;config는 컨테이너 레지스트리를 넘어서 배포가 되므로 클러스터에 직접 접근하지 않아도 확인가능하 다.\u0026rdquo; 라는 말인데, 흠\u0026hellip; 두가지 때문에 이말을 한것같은데 확실하게 모르겠다.\n   클러스터 내부로 들어가지 않아도 컨테이너 레지스트리에 접근 가능해서 하는 말이거나(몰랐음ㅋ) 컨테이너 레지스트리 파일시스템에서 확인 가능하므로 하는 말이거나    config가 컨테이너 이미지 안에 들어있으므로 Immutable하다.\n  복잡한 config도 다루기 쉬움. 사이즈가 큰 파일도 가능.\n  단점\n  라이프사이클이 복잡함, 이미지 빌드 관리 포인트가 늘어남.\n  민감한 데이터에 대한 concern이 없음.\n  환경 별로 다른 deployment가 필요. (또는 수정 필요)\n  👉그런데 내 생각에는, 이 방법은 복잡성이 높아서 왠만하면 피해야겠다.. 물론 버전관리가 된다는 점에서는 좋은 점 같긴하나 어플리케이션 개발에 따라 config도 변하기마련인데, 별도로 버전관리를 해야한다는게 오히려 짐이 늘어나는 것 같아 그리 장점으로 느껴지지가 않는다. 게다가 이 글을 쓰게된 처음 원칙을 떠올려보면, \u0026quot;config 변경으로 인해 Application의 빌드를 다시하면 안된다\u0026quot; 였는데 물론 Application 이미지는 그대로이긴하다. 그러나 이렇게 하는 이유로는 Application의 환경별 일관성도 있지만 개발자로서 개발하기 편하게 하기위함도있다. 그런데 이방법으로는 개발자는 괴로워질 것 같다.. CI/CD 면에서 관리 포인트도 늘어나고 config 수정이 매우 어려울 듯(hot reload도 불가능). \n4. Configuration Template    이 패턴은 3. Immutable Configuration에서 조금 진화된 것이라고 보면된다. 매우 복잡한 config이고 환경별로 거의 비슷한 config data를 가진다면 중복되는 부분이 많을 것이다. 따라서 일부 다른 부분만 바꿔주고 나머지 동일한 부분은 중복되어 리소스낭비를 줄일 수 있다.\n이 일을 하는 Configuration Template Tool들을 init container에서 사용하면 된다. Tiller (Ruby) or Gomplate (Go) 같은 것들이 있다.\n     이 패턴은 복잡성 때문에 config data가 매우 큰 경우에만 사용하는게 좋을 것이다.\n"},{"id":5,"href":"/Posts/3c3dba6f-8888-424b-a1a9-550cd213aee2/","title":"파이썬에 대한 몇가지 의문들","parent":"Posts","content":" 이 블로그는 Notion에서 랜더링 자동화를 통해 제작되었습니다.\nNotion 페이지에 최적화되어있습니다. → Notion에서 보기\n  1. 파이썬의 실행방식은 C언어 계열과 어떻게 다른가? 2. 파이썬은 언제, 왜, 어떤 것보다 느린가? 3. 파이썬을 선택하는 이유는 무엇인가? 4. \u0026lsquo;파이썬 내부는 C로 돈다\u0026rsquo; ? 5. CPython, Jython ? 6. 파이썬 내부 동작 7. Reference    그 동안 Python을 사용하면서 궁금했던 몇가지 의문들에 대한 답을 채워본다.\n 1. 파이썬의 실행방식은 C언어 계열과 어떻게 다른가?    파이썬은 스크립트 언어다. 스크립트 언어의 여러 특성 중 하나는 인터프리터 가 한줄씩 실행시켜 준다는 것이다. (이 때문에 대화형언어라고 한다.) 사용자는 파이썬 코드를 만들고 실행을 시키면 먼저 바이트코드 가 만들어진다. 이렇게 바이트코드가 만들어지는 과정을 파이썬에서의 컴파일이라 부른다. 그리고나서 인터프리터가 바이트코드를 한줄씩 읽고 실행시킨다.\n컴파일언어에서의 컴파일을 알고있다면 느꼈을 것이다. 파이썬에서의 컴파일은 C언어의 컴파일과 다르다. 파이썬에서 바이트코드까지 컴파일되었다면 C언어는 바이너리코드까지 완전 컴파일된다. 또한 최종적으로 링크라는 과정을 거쳐 해당 플랫폼에서 실행할 수 있는 실행파일까지 생성된다. 이 실행파일은 인터프리터 같은 중간다리없이 CPU에서 바로 실행된다.\n💡C코드 동작 방식 C언어 코드를 빌드과정을 다시 살펴보자. - 먼저 `컴파일러`가 C언어를 `어셈블리어`로 변환해 준다. - `어셈블러`가 어셈블리어를 `바이너리코드`로 바꿔준다. 어셈블리어는 CPU명령어이므로 CPU에 종속적이다. 여기까지가 C언어 코드를 바이너리코드까지 변환하는 과정이고 이를 컴파일이라고한다. 이후에는 `링커`가 시스템 라이브러리 함수 주소와 연결(Dynamic Linking) 또는 라이브러리를 포함(Static Linking)한다. 그러면 우리가 말하는 실행파일이 완성된다. 다음 슬라이드에 잘 나와있다. - [Programming Compile \u0026amp; Loading for Korean](https://prezi.com/obkhqdxaz3zx/programming-compile-loading-for-korean/) \n     2. 파이썬은 언제, 왜, 어떤 것보다 느린가?    위 1번 항목에서 파이썬의 동작방식은 인터프리터란 중간다리를 거쳐 실행된다 고 했다. 이것이 C, C++같은 완전컴파일 언어와의 차이점이다. 파이썬에서는 보통 빌드나 make같은 단계가 없다. 또한 파이썬의 바이트코드는 이진기계코드(intel or arm 칩 명령어)가 아니라 단순히 파이썬 고유 표현방식일 뿐이다.\n‌\n이것이 파이썬이 C, C++만큼 빠르지 않은 이유이다. 인터프리터(더 상세히는 PVM 루프. 6번 질문에서 조금 더 상세히 설명한다.)는 CPU 칩이 아니므로 여전히 바이트 코드를 머신코드로 해석해야하며, 바이트 코드 명령어들은 CPU 명령어보다 더 많은 작업을 해야한다. 다만 파이썬은 내부 컴파일 단계가 존재하므로 코드를 실행할 때마다 전통적인 인터프리터 언어와 같이 재분석, 재해석이 필요없어 전통적인 인터프리터 언어들보다는 빠르다.\n3. 파이썬을 선택하는 이유는 무엇인가?    그럼에도 파이썬을 사용하는 이유는 현대 컴퓨터 속도는 프로그램을 실행시키기에 충분히 빠르며 실행속도가 최적화되야하는 분야는 정해져있기 때문이다.\n다시말해 반드시 빨라야하는 분야가 아니라면 실행속도를 포기하고 파이썬으로 개발하였을 때 향상되는 개발 속도 면에서의 이득 이 더 크기 때문이다.\n‌\n또한 어느 정도의 속도 개선은 파이썬을 통해서도 해결 가능한 방법이 있다. 예를 들면 수치 연산 프로그래밍이라던가 애니메이션에서 핵심이 되는 방대한 수를 계산하는 컴포넌트에서 연산 속도가 나와야한다고 하자. 최적의 속도를 필요로하는 애플리케이션의 일부를 컴파일 확장으로 분리 하고, 이 확장을 파이썬 스크립트에서 사용하기 위해 그대의 시스템에 링크한다.\n‌\n이처럼 파이썬이 제어 언어로서의 역할을 하는 경우가 있다. NumPy 수치 연산 확장이 그 예이다. NumPy는 컴파일된 최적화된 수치 연산 확장 라이브러리를 파이썬 언어와 결합함으로써 효율적이고 사용하기 쉬운 수치 연산 프로그래밍 도구가 된다.\n‌\n파이썬은 다른 언어와 함께 사용할 수 있다.\n‌\n파이썬 프로그램은 다른 언어로 작성된 컴포넌트에 다양한 방법으로 쉽게 연결될 수 있다.\n‌\n예를 들어, 파이썬의 C API를 이용하면 C 프로그램에서 파이썬을 호출하거나 파이썬 프로그램에서 C 프로그램을 호출할 수 있다. 즉 필요하다면 C언어로 작성된 기능을 파이썬 시스템에 추가할 수 있고, 다른 환경이나 시스템에서 파이썬 프로그램을 이용할 수 있음을 의미한다.\n‌\n신속한 개발 속도를 위해 시스템을 먼저 파이썬으로 구현한 다음, 제품에 대한 성능 요구사항이 발생할 때 하나씩 C 코드로 옮겨 구현하는 개발 방법도 가능하다.\n4. \u0026lsquo;파이썬 내부는 C로 돈다\u0026rsquo; ?    먼저 \u0026ldquo;파이썬 내부\u0026quot;가 무엇인지 정확히 정의하자. 파이썬은 프로그래밍 언어를 의미할 수도 있고 인터프리터라고 불리는 소프트웨어 패키지를 의미할 수도 있다. 사용자가 파이썬 코드를 작성하면 인터프리터는 코드를 읽고 코드에 해당하는 명령을 수행한다.\n이때 인터프리터가 C로 구현되거나 자바로 구현되는 등 다양한 방법으로 만들어질 수 있다.\n우리가 표준으로 사용하고 있는 파이썬 인터프리터가 C로 만들어진 CPython을 사용하기 때문에 파이썬 내부가 C로 돌아간다고 말할 수 있는 지점이다.\n5. CPython, Jython ?    인터프리터의 종류이다. 위 4번 내용을 읽었다면 눈치챘겠지만 Jython이란 Java로 만들어진 인터프리터이다. 6. 파이썬 내부동작에서 더 자세하게 다룬다.\n6. 파이썬 내부 동작    사용자가 스크립트를 작성하면 인터프리터는 그 코드를 읽고 실행시킨다. 이때 인터프리터는 내부적으로 많은 일을 한다. 사용자가 스크립트 파일을 파이썬에게 실행하도록 명령했을 때, 다음 단계가 수행된다.\n‌\n 바이트코드(.pyc)라고 불리는 상태로 스크립트 파일을 컴파일한다.    바이트코드는 소스코드에 대한 저수준, 플랫폼 독립적인 표현이며 컴파일을 통해 소스코드의 statement는 개별적인 단계로 분해되서 바이트 코드로 그룹화된다. 이때 파이썬 프로그램의 종류(인터프리터의 종류)에 따라 바이트코드는 다를 수 있다.\n  그러니까 이 바이트코드만 있으면 어느 플랫폼에 가서도 실행 가능하다. 물론 해당 플랫폼에 파이썬 인터프리터가 설치되어있긴 해야한다. 컴파일된 인터프리터 종류도 같아야한다. Cython으로 컴파일한 파이트코드는 Jython으로 실행할 수 없다.\n       바이트코드는 파이썬 가상머신(PVM)이라고 불리는 곳에 전달된다.   PVM 이란 Python Virutal machine이란 뜻이며 바이트코드 명령을 차례로 반복 시키는 단순히 큰 루프이며 파이썬의 런티임 엔진 이다. 이 단계가 사실상 마지막 인터프리터 단계이다.‌  그런데 이러한 점들은 사용자에게 공개되지 않는다. 그럼으로써 사용자는 그저 파이썬 코드를 짜는데 집중할 수 있다. 사용자는 코드를 짜고 실행시키기만하면 된다.\n‌\n이런 일련의 과정들을 통틀어서 실행모델 이라고 한다. 인터프리터가 일하는 방식정도로 생각하면 된다. 실행모델은 위와같은 방식이 표준이지만 사용 용도에 따라 변형될 수 있다. 이러한 변형된 실행 모델들의 예가 CPython, Jython, IronPython, Stackless, PyPy 등 이다. 이들은 같은 파이썬 언어를 구현하지만 각기 다른 방식으로 프로그램을 실행한다. 즉 하나의 파이썬 소스를 각기 다른 방법으로 실행시킨다. Cython, Shed Skin 등의 모델도 있지만 이것들은 표준 파이썬 언어를 구현하지 않기 때문에 최적화 도구로서 볼수도 있다. 우리가 흔히 쓰는 파이썬 실행모델이며 표준인 모델은 CPython이다. CPython부터 시작해 몇가지 주요 실행모델을 정리해보았다.\n‌\n  CPython : 일반적으로 말하는 Python이다(표준). 이식성을 고려해 ANSI C언어로 구현되었다는 사실에서 CPython이란 이름이 붙었다.\n  Jython : 자바를 위한 파이썬이다. 자바 프로그래밍 언어와의 통합을 목적으로 한 파이썬 언어의 다른 구현이다. Jython은 파이썬 소스 코드를 자바 바이트 코드로 컴파일하고 생성된 바이트코드를 JVM으로 전달하는 자바 클래스로 구성되어있다. 개발자는 여전히 .py파일로 소스를 저장하고 Jython 시스템으로 실행시키면된다. 즉 파이썬 코드로 자바 애플리케이션 작성을 가능하게 한다. 런타임 시에는 실제 자바 애플리케이션처럼 보인다. CPython보다는 느리고 안정성이 떨어진다.\n  IronPython : .NET을 위한 파이썬. Jython과 매우 유사하다.\n  Stackless : 동시성을 위한 파이썬. Concurrency를 지향하는 표준 CPython언어의 재구현이며 향상된 버전이다. C언어의 call stack에 상태를 저장하지 않기 때문에 파이썬을 스택이 작은 아키텍처에 쉽게 이식할 수 있도록 하고, 효율적인 멀티프로세스 옵션을 제공하며 corrutine을 구현할 수 있다. 특히 microthread는 파이썬의 표준 멀티태스킹 도구인 스레드와 프로세스보다 효율적이고 가볍다.\n  PyPy: 속도를 위한 파이썬이다. 성능에 초점이 맞추어져 있다.\n  7. Reference    Learning Python - Mark Lutz 저\nhttps://cjh5414.github.io/about-python-and-how-python-works/\nhttps://github.com/Jpub/LearningPython\n"},{"id":6,"href":"/Posts/b18ceaba-6f84-4fd5-b80b-2404bd935d32/","title":"Python에서 GIL이란?","parent":"Posts","content":" 이 블로그는 Notion에서 랜더링 자동화를 통해 제작되었습니다.\nNotion 페이지에 최적화되어있습니다. → Python에서 GIL이란?\n  GIL이란?    그렇다면 파이썬은 왜 굳이 이러한 정책을 가지는 것일까? 그렇다고 Python의 멀티스레딩이 무조건 느린 것은 아니다.     Reference   GIL이란?    \nGIL이 무엇인지 설명하기 전에 Python으로 멀티스레딩과 일반적인 경우의 시간을 비교해본다. 시스템환경은 아래와 같다.\n     아래 코드는 5억개의 배열에 랜덤값을 집어넣고 최대값을 찾는 작업을 하나의 스레드와 두개의 스레드일 때로 나누어 실행하고 시간을 측정한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  import random import threading import time def working(): max([random.random() for i in range(100000000)]) # One Thread s_time = time.time() working() working() e_time = time.time() print(f\u0026#39;[One Thread] {e_time - s_time:.5f}\u0026#39;) # Two Threads s_time = time.time() threads = [] for i in range(2): threads.append(threading.Thread(target=working)) threads[-1].start() for t in threads: t.join() e_time = time.time() print(f\u0026#39;[Two Thread] {e_time - s_time:.5f}\u0026#39;)   당연히 멀티스레드일때 시간이 더 적게 걸렸을 것 같지만 실제로는 정반대의 결과다. 바로 GIL 때문이다.\n     GIL(Global Interpreter Lock)은 간단히 말해 뮤텍스로, 하나의 쓰레드만이 파이썬 인터프리터를 컨트롤할 수 있게 해주는 락이다. 쉽게말해 파이썬(Cython)에서는 스레드가 여러개 만들어두어도 바이트코드를 실행시킬 수 있는 스레드는 단 하나여야하는 정책이 걸려있고 이러한 정책을 구현해주는 것이 GIL이다.\n아래 그림에서 스레드는 세개지만 Lock이 걸리면서 동시간대에 바이트코드는 하나의 스레드만 실행할 수 있다. 물론 thread context switching까지 생각하면 싱글스레드보다 시간이 오래 걸리는 문제가 발생한다.\n     그렇다면 파이썬은 왜 굳이 이러한 정책을 가지는 것일까?    Python은 Garbage Collection과 Reference Counting을 통해 할당된 메모리를 관리한다. 따라서 파이썬의 모든 객체는 reference count, 즉 해당 변수에 참조된 수를 저장하고 있다. 여기서 문제가 발생한다. 멀티스레드인 경우 여러 스레드가 하나의 객체를 사용한다면 reference count를 관리하기 위해서 모든 객체에 대한 lock이 필요하다. 이러한 비효율을 막기 위해서 Python에서는 GIL을 사용하게 되었다. 하나의 Lock을 통해서 모든 객체들에 대한 Reference Count의 동기화 문제를 해결했다.\n그렇다고 Python의 멀티스레딩이 무조건 느린 것은 아니다.    아래 코드에서는 멀티스레드 동작이 더 빠르다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  import random import threading import time def working(): time.sleep(0.1) max([random.random() for i in range(10000000)]) time.sleep(0.1) max([random.random() for i in range(10000000)]) time.sleep(0.1) max([random.random() for i in range(10000000)]) time.sleep(0.1) max([random.random() for i in range(10000000)]) time.sleep(0.1) max([random.random() for i in range(10000000)]) time.sleep(0.1) # One Thread s_time = time.time() working() working() e_time = time.time() print(f\u0026#39;{e_time - s_time:.5f}\u0026#39;) # Two Threads s_time = time.time() threads = [] for i in range(2): threads.append(threading.Thread(target=working)) threads[-1].start() for t in threads: t.join() e_time = time.time() print(f\u0026#39;{e_time - s_time:.5f}\u0026#39;)   그 이유는 sleep 때문이다. 싱글스레드 작업에서는 sleep으로 인해 그대로 0.1초씩 쉬게된다. 그러나 멀티스레드에서는 sleep으로 멈춘 경우 다른 스레드로 context switching을 하기때문에 효율이 개선된다. 즉 하나의 스레드에서 sleep으로 멈추었을 때 다른 스레드가 동작하는 것이다.\n여기서는 sleep으로 대기상황을 재연했지만 I/O작업이 많은 경우도 이와 동일한 상황으로 볼 수 있다. I/O작업이 길고 빈번하다면 멀티스레드로 수행하는 것이 더 빠르다는 일반적인 결론을 내릴 수 있다.\nReference     https://ssungkang.tistory.com/entry/python-GIL-Global-interpreter-Lock은-무엇일까  "},{"id":7,"href":"/Posts/9de54b60-1288-45d0-9a55-ed2c85740606/","title":"Introduce To Database 스터디 회고록","parent":"Posts","content":" 이 블로그는 Notion에서 랜더링 자동화를 통해 제작되었습니다.\nNotion 페이지에 최적화되어있습니다. → Notion에서 보기\n   1. Database 스터디를 시작한 이유 2. 모집 3. 후기 4. 배운 것들 5. 회고  5.1 Database를 공부해야겠다고 느꼈던 순간 5.2 해결 방법 5.3 다시 그때로 돌아간다면?      약 2개월 간의 Database 스터디가 끝났다. 이 스터디를 시작한 이유가 무엇인지, 무엇을 배웠는지 후기를 남겨보려한다.\n 1. Database 스터디를 시작한 이유    컴퓨터공학과 학부시절, Database를 공부한다는 것이 정확히 어떤 것을 공부를 하는 것인지 몰랐다. 무엇보다 Database 공부의 필요성을 못느꼈다. 그 필요는 회사에서 개발을 시작하고나서야 느꼈다. 그 전까지는 필요를 느낄만한 경험이 부족했던 것 같다.\n경험을 통해 필요성을 느끼는 것이 무엇보다 큰 학습동기가 된다.\nDatabase 기초 지식에 대한 필요성을 처음 느낀 때는 회사에서 DynamoDB를 사용하는 프로젝트를 할 때였다. 서문이 길어질 것 같아 자세한 내용은 가장 문서 말미에 써야겠다.\n일단 개발자 커뮤니티에서 Database 기초 스터디가 있는지 찾아봤다. 스터디 모집글의 거의 95%는 Spring, 알고리즘, 프론트앤드 프레임워크 글이었다. 그래서 직접 모집을 시작했다.\n2. 모집    직접 모집을 하는 것의 좋은 점은 커리큘럼과 일정 등을 내 마음대로 결정할 수 있다는 점이다. 모집글은 최대한 자세하게 적었다. 아무 계획없이 사람만 모았다가 스터디가 산으로 가거나 그대로 해산하는 경우도 종종 목격했기 때문이다.\n소개, 모임 시간, 인원, 장소 그리고 무엇보다 스터디 방식과 계획을 자세하게 적었다. 아래는 스터디 모집글의 일부다.\n          3. 후기    스터디는 성공적으로 완료했다 👍 중간에 이탈하는 인원도 없었고 모두 끝까지 함께 해주셨다.\n나름 주최자라서그런지 가장 열심히 해야겠다는 책임감이 들었다. 그래서 모든 챕터를 문서로 남기려고 했다. 이렇게 했을 때 좋은 점은 발표자분께서 갑작스럽게 일이 생기더라도 내가 발표를 하고(공부도 더 된다) 스터디를 계속 진행할 수 있다는 점이다. 참여자분들은 다들 직장에 재직중이셨기 때문에 부담을 최대한 덜어드리려고 노력했다. 물론 내가 쉬고있는 상태라서 가능했다.\n그럼에도 불구하고 어쩔 수 없이 뛰어넘은 주차가 1~2회 정도 있었다. 여기서 느낀 것은 스터디가 한 주라도 미뤄지면 텐션이 떨어진다는 것이다. 특히 비대면 스터디라 더욱 크게 느껴졌다. 다음에도 이런 방식의 스터디를 한다면 차라리 발표자를 대체하고 강행하는 것이 나을 것 같다고 생각했다.\n참고로 강의는 그리 만족스럽지 않았다. 강사 본인의 유튜브채널 컨텐츠를 그대로 커리큘럼에 넣어놓았다. 그리고 정적인 영상을 띄워놓고 말만 주구장창해서 집중도와 이해도가 떨어진다.\n그래서 별한개 를 주었다 ^^\n4. 배운 것들    ACID\n  AICD란?\n  Isolation 레벨 별로 다른 트랜잭션 동작과 그에 따라 발생할 수 있는 문제들\n  Indexing\n  인덱싱이란?\n  Select 쿼리 시 내부에서 일어나는 일\n  Index Scan과 Index Only Scan의 차이\n  Where 조건에 따른 퍼포먼스 차이\n  Bitmap Index Scan vs Index Scan vs Table Scan\n  Bloom filters\n  Database Partitioning\n  Database Partitioning 이란?\n  Partitioning : Vertical vs Horizontal\n  Database Sharding\n Database Sharding 이란?  Concurrency Control\n  Lock이란?\n  Shared Locks vs Exclusive Lock\n  Two-Phase Locking\n  Database Replication\n  Database Replication 이란?\n  발생할 수 있는 동기화문제\n  동기화문제 해결 방안\n  Master-Backup vs Multi-Master Replication\n  Synchronous vs Asynchronous Replication\n    Row vs Column Oriented Database\n Row vs Column Oriented Database란 무엇이고 각각 어떤 용도로 사용하는가?  여러가지 DB 엔진\n  B-Tree Database Engine에는 어떤 것들이 있는지?\n  LSM Database Engine에는 어떤 것들이 있는지?\n  Database Cursor\n  Database Cursor란?\n  Server Side vs Client Side Database Cursors\n  5. 회고    머릿말에서 Database 기초 지식의 필요성을 회사에서 처음 느꼈다고 했다. 회사에서 있었던 일은 아래와 같다.\n5.1 Database를 공부해야겠다고 느꼈던 순간    회사에서 DynamoDB 를 사용하는 프로젝트에서 DB 기초 지식에 대한 필요성을 처음 느꼈다. 당시 Java 웹 어플리케이션 유지보수를 맡았었다. DB로는 AWS의 DynamoDB를 사용하고 있었다.\n그런데 어느날 검색기능과 선택 항목 삭제 기능을 추가해야하는 상황이 생겼다. 정말 단순한 일이라고 생각했다.\n DynamoDB에 필터를 걸어 find만 해주면 되겠구나. 그리고 그 결과로 항목을 삭제하면 되겠구나.\n 그런데 왠걸? 검색 결과 반환 시간이 몇십초 가 걸렸다. 게다가 단 한번의 검색에 DynamoDB 컴퓨팅 리소스가 미친듯이 치솟았다. 이는 곧 비용 증가를 의미했다. 그때부터 DynamoDB 도큐먼트를 샅샅이 읽기 시작했다. 범인은 1차원적이게도 DynamoDB 자체였다. DynamoDB는 NoSQL기반 DB로써 단순 Primary Key로의 접근은 빠르지만 적절한 설계 없이는 검색 성능이 매우 떨어지는 특징을 가지고 있기 때문이었다.\n검색이 아예 안되는 것은 아니었다. DynamoDB에서는 Partition Key 와 Sort Key 라는 개념이 있다. 이 두가지 Key를 가지고 사용할 수 있는 유즈케이스는 아래와 같다.\n하나의 필드를 Partition Key로 설정\n  이 경우, Partition Key는 Unique한 값으로 이루어져 있어야함.\n  Partition Key로 쿼리 시, Item 반환 (빠름)\n  하나의 필드를 Partition Key로 설정하고 다른 하나의 필드를 Sort Key로 설정\n  이 경우 Partition Key는 중복된 값으로 이루어져 있어도 됨.\n  Partition Key와 Sort Key로 쿼리 시, Sort Key 필드로 정렬되어있는 Item 배열 반환 (빠름)\n  예를들어, 아래 GameScores 테이블에서 Partition Key는 UserID 이고 Sort Key는 GameTitle 이다.\n     Partition Key와 Sort Key를 사용한 쿼리는 빠르다.\n \u0026ldquo;UserId 101번의 기록 중에 GameTitle 이 Starship X인 row를 줘\u0026rdquo;  그러나 아래와 같은 경우에는 매우 느리다.(전체 스캔 필요)\n  \u0026ldquo;GameTitle 이 Starship X인 것들 중에서 TopScore 가 가장 높은 row를 줘\u0026rdquo;\n  이러한 전체 스캔을 피하기 위해 인덱싱을 사용해야한다.\n  문제는 필드 개수가 많고 여러 필드를 사용한 조건으로 검색할 때다.\n아래 쿼리 케이스를 전체 스캔없이 반환하려면 인덱스가 필요하다.\n 검색조건 1 : \u0026ldquo;GameTitle 이 Starship X인 것들 중에서 TopScore 가 가장 높은 row를 줘\u0026rdquo; → Partition Key가 GameTitle 이고 Sort Key가 TopScore 인 인덱스 필요         검색조건 2 : \u0026ldquo;wins 가 1인 유저중에 가장 높은 TopScore 를 가진 row를 줘\u0026rdquo; → Partition Key가 wins 이고 Sort Key가 TopScore 인 인덱스 필요\n  검색조건 N : \u0026hellip;\n  필드가 더 많고 여러 조건이 조합된다면? 😱\n  검색조건이 복잡해질때 전체 스캔을 피하려면 수많은 인덱스를 생성해야하는 상황이 발생하는 것이다. 결국 DynamoDB를 고수한다면 검색조건에 제약이 생기거나 검색조건에 따라 데이터 반환 시간은 다르며 최악의 조건일 경우, 테이블 전체 스캔으로 몇십초 단위의 검색이 이루어진다.\n비용 폭탄은 덤이었다.\n5.2 해결 방법    이 서비스의 본질은 캐싱이다. 다시말해 클라이언트 측에서 이 서비스를 사용하는 이유는 속도 다. DynamoDB는 규모에 상관없이 짧은 지연시간을 보장하는 Key-Value DB라고 알려져있다. 즉 DynamoDB를 다른 Database로 교체하려면 어플리케이션의 유즈케이스에서 DynamoDB보다 빠른지 또는 느린지 체크해야하며 느릴경우 느린 정도가 합리적일지, 문제는 없는지 체크해야한다. 그리고 비용도 비교해봐야한다. 고려해야할 사항이 많았다. 검색기능 지원 하나를 위해서 함부로, 쉽게 DynamoDB를 다른 Database로 바꿀 수는 없었다.\n내부 논의 끝에 결국 DB를 갈아치우진 못하였다. 그 대신 DynamoDB Stream 기능을 사용하기로 했다. DynamoDB로 들어오는 Insert, Delete, Update 등의 Event를 Lambda로 받고 DocumentDB로 미러링 시켰다. 그렇게되면 검색은 DocumentDB에서 담당하게 되는데 속도가 나름 합리적이었다.\n검색기능 하나 때문에 DocumentDB를 사용하는 것은 낭비이긴 하지만 사내 일정 사정 상, 근본적인 해결은 Next Todo List로 남겼다.\n게다가 DocumentDB는 클러스터 형태라서 인스턴스가 3개 이상으로 돌아간다는건 안비밀\n5.3 다시 그때로 돌아간다면?    지금에 와서도 딱히 더 좋은 다른 해결책이 생각나진 않는다. 그러나 스터디에서 배운 개념들에 비추어 더 넓게 생각해볼 수 있을 것 같다. 서비스에서 고려해야할 부분뿐만 아니라 개인적인 호기심에서 비롯된 궁금증이 더 많아지고 더 많이 찾아봤을 것 같다.\n  우리 서비스에서 트랜잭션이 필요한 구간은 없는지? DynamoDB는 트랜잭션을 어떻게 구현할 수 있는지?\n  DynamoDB에서 Isolation level을 설정할 수 있는지? 그렇게 해서 일관성을 얻을 수 있는지? 그러한 일관성이 우리 서비스에서 필요한지? 아니면 일관성을 일부 포기하고 퍼포먼스를 선택하는게 더 좋을지?\n  Postgresql에서는 특정 row에 접근해 attributes를 가져올 때 Heap에서 random access로 가져올텐데 DynamoDB에서는 Partition Key를 통해 특정 row에 접근 후 다른 attributes를 불러올 때 어떻게 가져오는지?\n  DynamoDB에서 Partition Key로 쿼리를 하면 Hash함수를 통해 특정 값에 도달할 수 있다는데 Hash Collision은 없는지? 당연히 없게 만들어져있겠지만 어떤식으로 피하는지?\n  "},{"id":8,"href":"/Posts/6853b939-a455-4530-8ced-8fc779a2500e/","title":"Git Action으로 Notion과 Hugo 블로그 동기화하기(Geekdoc Theme)","parent":"Posts","content":" 이 블로그는 Notion에서 랜더링 자동화를 통해 제작되었습니다.\nNotion 페이지에 최적화되어있습니다. → Notion에서 보기\n  1. 무엇이 필요했는지? 2. 정적블로그와 테마 선택하기 3. Github.io에 정적블로그 생성하기 4. Notion 페이지 정보 가져오기 5. 자동화하기 6. 결론   1. 무엇이 필요했는지?    지금까지 몇번이고 블로그 운영과 문서화 시도를 해왔다. 그러나 어느것하나 내가 원하는 기능을 만족시키는 제품이 없었다. 되돌아보니 지금까지 정말 여러 서비스들을 거쳐왔다.\n 네이버 블로그, 티스토리, 워드프레스, OneNotes(MS), Gitbook, Github 정적블로그 등등..  그런데 무엇하나도 완벽한 것이 없었다. 티스토리와 같은 블로그 서비스들은 테마나 UI가 너무 고정적이다. OneNotes는 에디터의 자유도가 지나치게 높다. Gitbook이 그나마 내가 원하는 바와 가장 맞았다. 그러나 Gitbook도 막상 써보니 생각지못한 곳에서 문제가 많았다. (한글문제라던가.. 등등) Github 정적블로그는 편집이 까다로웠다.\n결국 나는 Notion 에 정착했다. 충분한 편집 자유도, 웹페이지 노출, 다양한 DB, 문서를 카테고리화하여 정리 등등 내가 원하는 찾던 도구에 거의 완벽했다. 특히 에디터는 완벽 이상이었다.\n단 하나의 흠이라고한다면 Notion을 블로그로 사용하기 어렵다는 것 이다. Notion으로 글을 작성하고 정적블로그에 손수 옮기는 작업도 참으로 개고생인듯했다. 그래서 이런 방법을 생각했다.\nNotion으로 문서를 편집하고 Github 정적블로그로 렌더링을 시키는 것!\n이 문서에서는 구현 방법에 대한 자세한 내용보다는 어떤 문제가 있었고 이를 해결하기위해 어떤 방법을 사용했는지 정도의 흐름으로 정리했다.\n2. 정적블로그와 테마 선택하기    정적블로그 제너레이터는 여러가지가 있다. 그 중에서 Hugo 를 선택했다. 그리고는 Hugo Theme 을 둘러보았다. 내가 찾는 테마의 조건은 이렇다.\n  Left Navigation기능이 있고 Category Expanding을 지원해야한다.\n  최대한 깔끔\n  Shortcodes(embed, Expand, image size 조절 등)도 풍부했으면 좋겠다.\n  커스터마이징도 가능해야함.\n  다크모드, 화이트모드 모두 지원했으면 좋겠다.\n  여러 테마를 직접 받아서 테스트해보고 최종적으로 선택한 테마는 hugo-geekdoc 였다.\n     특히 hugo-geekdoc은 다양한 Shortcuts를 지원하고있기 때문에 Notion의 다양한 종류의 Block을 표현할 수 있을 것이라고 생각했다. Notion에서는 페이지를 이루고있는 요소 하나하나(Text Type, Numbered List 등)를 Block이라는 단위로 부른다.\n테마 칼라도 각자 입맛에 맞게 수정한다. footer와 header 등 각 컴포넌트도 커스터마이징이 가능하니 이 부분도 입맛에 맞게 수정한다.\n나는 색을 최소한으로 사용하도록 수정했다. 그리고 footer에 댓글기능을 추가했다.\n     참고로 hugo-clinic-notes 이 테마도 정말 깔끔하다. (깔끔하기만 하다.)\n3. Github.io에 정적블로그 생성하기    github.io에 정적블로그를 배포하는 방법은 찾아보면 매우 많다.\n     여기서는 작은 팁을 하나 공유하고자한다. 우리가 github page에 넣어놓아야 하는 것은 Hugo 빌드를 통해 나온 결과물이다. 어떤 분들은 Hugo 정적파일들과 Hugo 빌드 결과물을 다른 레포지토리에 놓는 경우도 있던데 나는 그것이 더러워보였다. 그래서 브랜치로 나누어 놓았다.\n  main 브랜치 : Hugo 정적 파일\n  gh-page 브랜치 : Hugo 빌드 결과물\n            그리고나서 git action을 사용해 main브랜치에 커밋(푸시)이 발생되었을 때 빌드가 된 후 gh-page에 배포되게 했다. 자세한 방법은 actions-gh-pages 을 참고하면 된다. git action에 대한 내용은 아래에서 다시 기술하겠다.\n4. Notion 페이지 정보 가져오기    이제 할 일은 Notion 페이지의 Block에 접근해야 하는 것이다. Notion에서 공식적으로 API를 제공하긴 하지만 아직 베타버전이며 텍스트 타입 Block만 지원한다. 즉 이미지 같은 블럭은 읽을 수 없다는 것이다. 다행히 Unofficial Notion API이지만 Official보다 괜찮은 파이썬 라이브러리가 있었다.\n notion-py  이제 이것으로 Notion페이지를 읽고 hugo-geekdoc에 맞게 변환하여 Markdown 파일을 만들어 주어야 한다. 이 부분은 파이썬 패키지로 만들어놓았다.\n https://github.com/hwangseonbi/notion2geekdoc  간단히 설명하자면 아래와 같이 Notion 페이지 하나에 테이블을 놓는다. 테이블은 여러개를 놓을 수 있다. 이렇게 여러 개의 테이블을 포함한 페이지를 Root Page 라고 정의했다.\n     그후 이 Root Page URL 주소로 notion2geekdoc 모듈을 실행시키면 아래 Left Navigation과 같이 테이블 단위로 카테고리화된다. 그리고 Status Property 가 Published 인 문서들이 geekdoc theme에 꼭 맞게 랜더링된다! 자세한 사용법은 README.md 에 적어놓았다.\n     그러나 우리는 이 패키지를 직접 사용하지 않을 것이다 😓\n글을 작성하거나 편집할 때마다 파이썬 패키지를 실행시키고 Hugo 빌드 결과물을 Github에 커밋한다는 것\u0026hellip; 또한 엄청난 노가다 이다.\nNotion에 글만 써놓으면 알아서 블로그에 연재되게 할 수는 없을까?\n5. 자동화하기    지금까지의 작업들을 자동화해줄 방법을 생각해보았다. 개인 서버에서 스크립트를 짜고 crontab을 돌릴까도 생각해보았지만 찾다보니 멀지않은 곳에서 괜찮은 방법을 찾을 수 있었다.\n     그 동안 힐끗힐끗 신경쓰였던 Github의 Actions 탭이다. 알아보니 빌드, 테스트, 배포 등 다양한 작업을 할 수 있었다. 하나의 큰 작업을 workflow라고 한다. workflow 안에서는 언제 이 workflow가 실행될지 trigger를 정의하고 job과 step 단위로 할 일을 정의할 수 있다. 더 멋진 것은 이러한 workflow를 패키지화하여 다른 사람들과 공유할 수 있다는 것이다.\n예를들어 Hugo 빌드 환경 을 갖추기 위해서는 Hugo를 설치하는 등의 작업을 거쳐야한다. 그런데 이러한 일련의 과정들을 하나의 action으로 만들 수 있다. 우리는 직접 hugo를 설치하는 과정을 정의할 필요가 없다. Hugo를 설치하는 작업들은 peaceiris/actions-hugo@v2 에 패키징 되어있다. 아래와 같이 Git Action workflow 정의파일에서 step을 정의할 때 peaceiris/actions-hugo@v2 을 거치면 그 이후 step부터는 Hugo를 사용할 수 있는 상태가 된다.\n1 2 3 4 5  - name:Setup Hugouses:peaceiris/actions-hugo@v2with:hugo-version:\u0026#39;0.81.0\u0026#39;# extended: true   아무튼 나는 아래 순서로 작업들이 실행되게 만들었다.\n  매일 하루에 한번씩 notion2geekdoc 모듈을 실행\n  notion2geekdoc 모듈을 실행한 결과물(contents )을 hugo에 포함해 빌드한다.\n  hugo로 빌드한 최종 결과물을 github.io에 커밋\u0026amp;푸쉬한다.\n  매일 하루에 한번씩 workflow가 실행되게 하려면 scheduled-events 트리거를 사용하면 된다. 나는 매일 UTC기준 00:00에 빌드가 되도록 설정했다. 한국 시각은 09:00이다.\n1 2 3 4  name:cron_sync_notion_scheduleron:schedule:- cron:\u0026#39;0 0 * * *\u0026#39;   그리고 Job을 두 부분으로 나누었다. 하나는 notion2geekdoc을 실행하는 Job(render_from_notion )이다. 여기서 contents 디렉토리가 만들어진다. 다른 하나의 Job은 render_from_notion 에서 만들어진 contents 를 가지고 Hugo 빌드를 하고 배포하는 Job(deploy_content )이다.\n이때 Job 간에 contents 를 공유해야한다. 하지만 Job은 별도의 VM 환경에서 실행되기 때문에 파일시스템이 공유되지 않는다. 따라서 우리는 Job 간에 contents 를 공유할 수 있도록 해야한다. 이러한 일을 download-artifact Action이 해준다.\n자세한 workflow 정의는 cron_sync_notion_scheduler.yml 에서 확인할 수 있다. 아래는 매일 한번씩 실행된 git action 기록들을 보여준다.\n     마지막으로, 테스트할 때 cron을 trigger로 사용하는 것은 비효율적이다. 사용자가 원하는 시점에 원하는 변수로 trigger하는 방법으로 manual-events 라는 방법이 있다. 아래와 같이 정의하며 실행할 때마다 input으로 사용자가 원하는 값을 전달할 수도 있다.\n1 2 3 4 5 6  on:workflow_dispatch:inputs:root_page_url:description:\u0026#39;Root Page URL(public)\u0026#39;required:true        6. 결론    이 기록은 아무래도 설명서가 아닌 경험담이기 때문에 자세한 구축방법을 써놓진 않았다. 그리고 이런식으로 툴을 활용한 시스템 구축은 한번 만들어놓고 자세한 문서를 만들어놓지 않으면 나중에 다시 보았을 때 파악하기 힘들다.\n \u0026lsquo;이게 왜 되고있는 거지?'\n\u0026lsquo;이런 일은 누가 해주는거지?'\n 이런 상황을 방지하려면 Zerobase에서도 구축할 수 있는 설명서가 되면 좋다. 그러나 더 좋은 것은 장황한 문서를 안보고도 쉽게 구축할 수 있는 것이다. 아래 작업들로 훨씬 편하게 만들 수 있을 것 같은데 이것들은 Next로 남겨두어야겠다.\n  notion2geekdoc모듈의 setuptools 설정 등 사전 작업 및 pypi 등록\n  하나의 git action으로 위 작업들이 자동화되게끔 git action 제작 또는 Docker conatiner image 제작 (가능할까?)\n  "},{"id":9,"href":"/Algorithm/","title":"Algorithm","parent":"@hwangseonbi","content":""},{"id":10,"href":"/Frontend/79ac381b-6bb1-4b0b-96a2-d440d0302a78/","title":"CSS Box 모델에 대하여","parent":"Frontend","content":" 이 블로그는 Notion에서 랜더링 자동화를 통해 제작되었습니다.\nNotion 페이지에 최적화되어있습니다. → Notion에서 보기\n  1. \u0026lt;div\u0026gt;로 박스먼저 만들기 2. boder 속성 살펴보기 3. 사각형 내부에 다른 요소가 들어있다면? 4. 그러면 외부 요소와 간격을 벌리고 싶을 땐? 5. 직접 계산해보기   크롬의 개발자도구 탭에서 요소를 검사할 때마다 나타나는 저 박스들\n     항상 궁금했었다. 도대체 무엇을 의미하는가\u0026hellip; 🥵\n 1. \u0026lt;div\u0026gt;로 박스먼저 만들기    padding이 뭔지 margin이 뭔지 정의 부터 보기전에 \u0026lt;div\u0026gt;태그로 사각형을 먼저 만들어보자.\nheight, width 속성으로 사이즈를 조절할 수 있다. 그리고 이에따라 주변의 요소들은 밀려나게된다.\n말끔한 날것의(?) blue 사각형이 만들어진다.\n     2. boder 속성 살펴보기    두번째로 볼 속성은 border이다. border 속성의 기본값은 none이라서 별도의 속성값을 주지 않으면 위에서 보았던 것처럼 경계선은 보이지 않게된다.\nsolid값을 줘보자. 그러면 사각형 테두리에 3px(기본값)짜리 경계선이 둘러쌓인다.\n중요한 것은 전체적인 div의 크기는 커졌지만 알맹이 사각형의 크기는 그대로인 상태에서 border의 픽셀수만 추가되었다는 것이다.\n     border-width 속성값을 많이주면 더 극명하게 차이가 보인다. 물론 0px로 설정하면 border는 사라지게 된다.\n     3. 사각형 내부에 다른 요소가 들어있다면?    이제 div 사각형 내부에 다른 요소가 들어있다고 해보자.\n     이때 글자들이 너무 왼쪽에 붙어있어 조금 여유를 두고싶을 때가 있다. 이럴 때 사용하는 것이 padding이다.\n     4. 그러면 외부 요소와 간격을 벌리고 싶을 땐?    반대로 외부요소와 외부요소 사이의 간격을 벌리고 싶을때 사용하는 것이 margin이다.\n     다음 예시를 보자. \u0026lt;div\u0026gt;태그 안에 \u0026lt;h1\u0026gt;태그와 \u0026lt;p\u0026gt;태그가 포함되어있는 단순한 html이다.\n     개발자 도구에서 보면 \u0026lt;p\u0026gt;태그에 margin이 들어간 것을 볼 수 있다. 이 값 때문에 \u0026lt;p\u0026gt;태그 위에있는 \u0026lt;h1\u0026gt;태그와 공간이 벌어져있는 것을 볼 수 있다. 주황색으로 표시된 부분\n5. 직접 계산해보기    컨텐츠의 영역을 직접 계산하여 아래와 같이 꼭지점을 잇는 사각형을 만들어보면 박스모델을 제대로 이해할 수 있다.\n     1 2 3 4 5 6  \u0026lt;div class=\u0026#34;container1\u0026#34;\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;container2\u0026#34;\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;container3\u0026#34;\u0026gt; \u0026lt;/div\u0026gt;   아래 CSS 코드의 주석 처리된 부분을 풀면 위 결과물이 만들어진다. 왜 저만큼의 픽셀이 밀어져야하는지 생각해보시길.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  * { margin:0px; } .container1 { width:100px; height:100px; border:solid; border-width:5px; background-color:blue; /* margin-left:10px; */ } .container2 { width:100px; height:100px; background-color:red; border:solid; border-width:10px; /* margin-left:120px; */ } .container3 { width:100px; height:100px; background-color:yellow; border:solid; border-width:10px; /* margin-left:240px; */ }   ▼ 전역 속성 설정 이유 ↕  과제를 하다보면 이렇게 margin값을 주지 않았음에도 사각형 주위에 빈공간이 생긴다.\n     그 이유는 기본값 때문이다. 우리가 아무 속성값을 지정하지 않아도 기본적으로 \u0026lt;body\u0026gt;태그에 설정된 속성들이 있다. 그 중에서 margin이 8px으로 기본적으로 적용되어 있다.\n그래서 이렇게 \u0026lt;body\u0026gt;를 비롯한 모든 기본 margin값을 0px로 설정해놓은 것이다.\n  "},{"id":11,"href":"/Algorithm/6deb1329-a0df-4511-b16e-ead4ac2248a5/","title":"다익스트라 최단거리 알고리즘에 대하여","parent":"Algorithm","content":" 이 블로그는 Notion에서 랜더링 자동화를 통해 제작되었습니다.\nNotion 페이지에 최적화되어있습니다. → Notion에서 보기\n  1. 다익스트라 알고리즘 2. 아이디어 3. 알고리즘 4. 일반화 5. 구현 6. 문제    1. 다익스트라 알고리즘    그래프들 간에 최단거리를 구할 수 있는 알고리즘이다.\n2. 아이디어    사실 다익스트라 알고리즘은 아래 그래프를 보고 최단거리를 구하려할때 나를 포함한 보통의 사람들이 떠올리는 생각의 순서와 비슷하다. 아래 그래프상에서, A에서 B까지의 최단거리를 생각해보자.\n       직접 연결된 곳 먼저 가보자 A→B : 100 얼라? 거리가 좀 커보이네?\n  다른 곳 거쳐서 가보자 A→C→B : 400+2 = 402 중간에 400 때문에 더 걸리네..\n  더 둘러가볼까 A→C→E→B = 2+4+1=7 거리값이 적은 곳으로 돌아오니 빠르군\n  여기서 주목할 포인트는 3번과정이다.\n3번 과정을 통해서 우리는 D 또는 E지점으로 갈때 A→B가 아닌 A→C를 거쳐야 최소값이 될 것 같다는 생각이 든다. 즉 어떤 지점까지의 최단거리는 그 이전 지점들까지의 최단거리로 이루어진다는 아이디어다.\n✅__다익스트라 알고리즘의 핵심__ : 특정 지점에서 목표 지점까지의 최단 거리는 목표 지점과 인접한 지점까지의 최단 거리로 이루어진다. \n다시말해, E지점까지의 최단거리는 E와 인접한 노드인 B, C, D 중 한곳을 거쳐와야할 것이고, 그렇다면 A→E 최단거리는 A→B의 최단거리 또는 A→C의 최단거리 또는 A→D의 최단거리를 통해서 얻을 수 있는 것이다.\n3. 알고리즘    위 사고를 조금 더 체계화시켜보자.\n  A를 시작노드로 설정한다.\n  현재노드는 A이다. A와 인접한 노드의 간선을 계산한다.\n       A는 시작노드이며 자기 자신으로 가는 거리는 0이다. A에서 D나 E로 가는 거리는 아직 모른다.\n다음 방문할 노드를 선택한다. 선택기준은 아래와 같다.    아직 방문하지 않은 노드이면서\n  가장 가까운 노드\n  A와 인접한 노드 중에서 가까운 곳은 C이다.\nC노드는 D, E, B와 연결되어있다. 지금까지 구한 C까지의 최단거리(2)를 통해 몰랐던 D,E의 최단거리를 알아낼 수 있다. 어쩌면 지금까지 구한 B까지의 최단거리보다 C를 통해 B까지 가는 거리가 더 빠를 가능성도 있다.       아쉽게도 C를 거친 B까지의 거리는 402으로 기존 최단거리보다 더 길다. 따라서 갱신하지 않는다.\n현재까지 A, C노드를 방문하였다. 모든 노드를 방문할 때까지 3번 과정부터 다시 반복한다.  4. 일반화    다시 일반화 시켜보면 아래와 같이 정리 가능하다.\n  출발 노드 설정\n  출발 노드를 기준으로 각 노드의 최소 비용을 저장\n  방문하지 않은 노드 중에서 가장 비용이 적은 노드 선택\n  해당 노드를 거쳐서 특정한 노드로 가는 경우를 고려하여 최소 비용 갱신\n  모든 노드를 방문완료할 때까지 3번 ~ 4번을 반복\n  ⚠️코드 구현 시, 3번 과정에서 비용이 가장 적은 노드를 선택할 때 배열을 돌면서 찾을 수도 있다. 하지만 우선순위 큐로 구현한다면 더 빠르게 찾을 수 있다. \n5. 구현    1 2 3 4 5 6 7  graph = { \u0026#39;A\u0026#39;: {\u0026#39;B\u0026#39;: 100, \u0026#39;C\u0026#39;: 2}, \u0026#39;B\u0026#39;: {\u0026#39;C\u0026#39;: 400, \u0026#39;E\u0026#39;: 1}, \u0026#39;C\u0026#39;: {\u0026#39;E\u0026#39;: 4, \u0026#39;D\u0026#39;: 2}, \u0026#39;D\u0026#39;: {\u0026#39;E\u0026#39;: 3}, \u0026#39;E\u0026#39;: {} }   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  def dijkstra_using_adj(graph, start): def get_min_node(current_node, graph, visited): min_node = None min_distance = float(\u0026#39;inf\u0026#39;) for node, distance in graph[current_node].items(): if visited[node] != False: continue if min_distance \u0026gt; distance: min_distance = distance min_node = node if min_node == None: for node, is_visited in visited.items(): if not is_visited: min_node = node return min_node shortest_distances = {node: float(\u0026#39;inf\u0026#39;) for node in graph} shortest_distances[start] = 0 shortest_distances.update(graph[start]) visited = {node: False for node in graph} visited[start] = True current_node = start while False in visited.values(): current_node = get_min_node(current_node, graph, visited) for node, d in graph[current_node].items(): new_distance = shortest_distances[current_node] + d if shortest_distances[node] \u0026gt; new_distance: shortest_distances[node] = new_distance visited[current_node] = True return shortest_distances   1 2 3 4  print(\u0026#34;--graph--\u0026#34;) print(graph) print(\u0026#34;---------------------\u0026#34;) print(dijkstra_using_adj(graph, \u0026#34;A\u0026#34;))        6. 문제    heapq를 사용하여 인접 노드 중 가장 가까운 노드를 빠르게 구해볼 수 있다. heapq방식으로 백준 1753 문제를 풀어보았다. 4.일반화의 3번과정(방문하지 않은 노드 중에서 가장 비용이 적은 노드 선택)을 뺐다. 방문했는지 여부는 사실 if new_distance \u0026amp;lt; SHORTEST_DISTANCES[adj_node]: 조건을 통해서 알 수 있기 때문이다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  import sys from heapq import heappush, heappop INF = 100000000 V, E = map(int, sys.stdin.readline().split()) K = int(sys.stdin.readline()) GRAPH = [[] for _ in range(V + 1)] SHORTEST_DISTANCES = [INF] * (V + 1) heap = [] def dijkstra(start): SHORTEST_DISTANCES[start] = 0 heappush(heap, (SHORTEST_DISTANCES[start], start)) while heap: current_distance, current_node = heappop(heap) for adj_node, d in GRAPH[current_node]: new_distance = current_distance + d if new_distance \u0026lt; SHORTEST_DISTANCES[adj_node]: SHORTEST_DISTANCES[adj_node] = new_distance heappush(heap, (new_distance, adj_node)) for i in range(E): u, v, w = map(int, sys.stdin.readline().split()) GRAPH[u].append((v, w)) dijkstra(K) for d in SHORTEST_DISTANCES[1:]: print(d if d != INF else \u0026#34;INF\u0026#34;)   주의할 점은 heapq.heapush() 함수 사용 시, 튜플을 인자로 줄 때다. 튜플을 잘못쓰면 오히려 시간초과가 발생할 수 있다.\nheappush 인자로 heappush(heap, (new_distance, adj_node)) 대신 heappush(heap, (adj_node, new_distance)) 을 전달했다. 이럴경우 heappop()을 호출했을 때 distance가 최소인 노드가 반환되지 않고 adj_node 값이 최소인 노드를 반환하게된다. 즉 그냥 노드번호가 가장 낮은 노드가 반환되는 것이다.\n반드시 Reference-heapq를 잘 확인해보고 사용하자.\n"},{"id":12,"href":"/","title":"@hwangseonbi","parent":"","content":"\nHi, I\u0026rsquo;m Taehoon.  About Me I live in Korea 🇰🇷 and work as an Backend Developer 👨‍💻. I\u0026rsquo;m fond of sports 🔥 and especially like playing futsal ⚽. You can also find me in  Github,  Notion.  Here`](google.com) are some projects I have made. -- "},{"id":13,"href":"/categories/","title":"Categories","parent":"@hwangseonbi","content":""},{"id":14,"href":"/tags/","title":"Tags","parent":"@hwangseonbi","content":""}]